#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
RAG (Retrieval Augmented Generation) í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Vector DB â†’ GPT-5 íŒŒì´í”„ë¼ì¸ ê²€ì¦
"""

import asyncio
import sys
import logging
from pathlib import Path

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent))

from app.services.rag_service import RAGService


async def test_search_similar_stocks():
    """ìœ ì‚¬ ì£¼ì‹ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 80)
    logger.info("[TEST 1] Search Similar Stocks")
    logger.info("=" * 80)

    rag = RAGService()

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_queries = [
        "AI ê¸°ì—…",
        "ë°˜ë„ì²´ íšŒì‚¬",
        "Appleê³¼ ìœ ì‚¬í•œ ê¸°ì—…",
        "í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ì œê³µì—…ì²´"
    ]

    for query in test_queries:
        logger.info(f"\nğŸ” Query: '{query}'")
        result = await rag.search_similar_stocks(query, top_k=3)

        if result.get("status") == "success":
            logger.info(f"âœ… Found {result.get('total_results')} results:")
            for idx, stock in enumerate(result.get("results", []), 1):
                symbol = stock.get("symbol", "N/A")
                name = stock.get("company_name", "N/A")
                score = stock.get("similarity_score", 0)
                sector = stock.get("sector", "N/A")
                price = stock.get("current_price", 0)
                logger.info(f"   {idx}. {symbol} ({name}) - Score: {score*100:.1f}%")
                logger.info(f"      Sector: {sector}, Price: ${price:,.2f}")
        else:
            logger.error(f"âŒ Search failed: {result.get('reason')}")


async def test_generate_context():
    """RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 80)
    logger.info("[TEST 2] Generate RAG Context")
    logger.info("=" * 80)

    rag = RAGService()

    query = "ê¸°ìˆ ì£¼ ì¤‘ì—ì„œ ê°€ì¥ ì•ˆì •ì ì¸ ê¸°ì—…ì€?"

    logger.info(f"\nğŸ“ Generating context for: '{query}'")
    result = await rag.generate_rag_context(query, top_k=3)

    if result.get("status") == "success":
        logger.info("âœ… Context generated successfully!")
        logger.info(f"\n[Context Preview (first 500 chars)]:")
        context = result.get("context", "")
        logger.info(context[:500] + "...")
        logger.info(f"\n[Total sources: {result.get('total_results')}]")
    else:
        logger.error(f"âŒ Context generation failed: {result.get('reason')}")


async def test_rag_query():
    """RAG ì¿¼ë¦¬ í…ŒìŠ¤íŠ¸ (GPT-5 í˜¸ì¶œ)"""
    logger.info("\n" + "=" * 80)
    logger.info("[TEST 3] RAG Query with GPT-5")
    logger.info("=" * 80)

    rag = RAGService()

    test_queries = [
        "í˜„ì¬ ì‹œì ì—ì„œ AI ê¸°ì—…ë“¤ì˜ íˆ¬ì ê°€ì¹˜ëŠ” ì–´ë–»ê²Œ ë˜ë‚˜?",
        "ë°˜ë„ì²´ ê¸°ì—…ë“¤ ì¤‘ ì–´ëŠ ê¸°ì—…ì´ ê°€ì¥ ì‹¤ì ì´ ì¢‹ì€ê°€?",
        "ê¸°ìˆ  ëŒ€í˜•ì£¼ë“¤ì˜ ê³µí†µì ì€ ë¬´ì—‡ì¸ê°€?"
    ]

    for query in test_queries:
        logger.info(f"\nğŸ’¬ Query: '{query}'")
        logger.info("â³ Calling GPT-5 with RAG context...")

        result = await rag.query_with_rag(query, top_k=3)

        if result.get("status") == "success":
            logger.info("âœ… GPT-5 Response received!")
            response = result.get("response", "")
            logger.info(f"\n[Response (first 800 chars)]:")
            logger.info(response[:800] + "...")
            logger.info(f"\n[Source Symbols: {result.get('source_symbols')}]")
        else:
            logger.error(f"âŒ Query failed: {result.get('reason')}")


async def test_stock_comparison():
    """ì¢…ëª© ë¹„êµ ë¶„ì„ í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 80)
    logger.info("[TEST 4] Stock Comparison Analysis")
    logger.info("=" * 80)

    rag = RAGService()

    comparison_pairs = [
        ("AAPL", "MSFT"),
        ("NVDA", "AMD"),
        ("TSLA", "F")
    ]

    for symbol_1, symbol_2 in comparison_pairs:
        logger.info(f"\nâš–ï¸  Comparing {symbol_1} vs {symbol_2}")
        logger.info("â³ Analyzing comparison...")

        result = await rag.compare_stocks(
            symbol_1=symbol_1,
            symbol_2=symbol_2,
            analysis_type="comprehensive"
        )

        if result.get("status") == "success":
            logger.info("âœ… Comparison analysis complete!")
            comparison = result.get("comparison", "")
            logger.info(f"\n[Comparison (first 600 chars)]:")
            logger.info(comparison[:600] + "...")
        else:
            logger.warning(f"âš ï¸  Comparison not available: {result.get('reason')}")


async def test_vector_search_flow():
    """ì „ì²´ ë²¡í„° ê²€ìƒ‰ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    logger.info("\n" + "=" * 80)
    logger.info("[TEST 5] Complete Vector Search Flow")
    logger.info("=" * 80)

    rag = RAGService()

    logger.info("\nğŸ“‹ Step 1: Generate Query Embedding")
    query = "ë†’ì€ ë°°ë‹¹ê¸ˆì„ ì§€ê¸‰í•˜ëŠ” ëŒ€í˜• ê¸°ì—…"
    query_embedding = await rag.openai_service.generate_embedding(query)

    if query_embedding:
        logger.info(f"âœ… Embedding generated: {len(query_embedding)} dimensions")

        logger.info("\nğŸ“ Step 2: Search Pinecone for Similar Vectors")
        similar = await rag.pinecone_service.query_similar_stocks(
            query_embedding=query_embedding,
            top_k=3
        )
        logger.info(f"âœ… Found {len(similar)} similar stocks")

        logger.info("\nğŸ’¾ Step 3: Enrich with Additional Data")
        enriched = await rag._enrich_search_results(similar)
        logger.info(f"âœ… Enriched {len(enriched)} stocks with detailed data")

        logger.info("\nğŸ“ Step 4: Build Context for GPT-5")
        context = rag._build_context_text(query, enriched)
        logger.info(f"âœ… Context built: {len(context)} characters")

        logger.info("\nğŸ¤– Step 5: Send to GPT-5")
        messages = [
            {
                "role": "system",
                "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ê¸ˆìœµ ë¶„ì„ê°€ì…ë‹ˆë‹¤."
            },
            {
                "role": "user",
                "content": f"{context}\n\nì§ˆë¬¸: {query}ë¥¼ ì œê³µí•˜ëŠ” ê¸°ì—…ë“¤ì˜ íŠ¹ì§•ì€?"
            }
        ]

        response = await rag.openai_service.async_chat_completion(
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )

        if response:
            logger.info("âœ… GPT-5 Response received!")
            logger.info(f"\n[Analysis (first 500 chars)]:")
            logger.info(response[:500] + "...")
        else:
            logger.error("âŒ GPT-5 call failed")
    else:
        logger.error("âŒ Embedding generation failed")


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    logger.info("\n" + "=" * 80)
    logger.info("ğŸš€ RAG Integration Test Suite Starting")
    logger.info("=" * 80)

    try:
        # í…ŒìŠ¤íŠ¸ 1: ìœ ì‚¬ ì£¼ì‹ ê²€ìƒ‰
        await test_search_similar_stocks()

        # í…ŒìŠ¤íŠ¸ 2: ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        await test_generate_context()

        # í…ŒìŠ¤íŠ¸ 3: RAG ì¿¼ë¦¬
        await test_rag_query()

        # í…ŒìŠ¤íŠ¸ 4: ì¢…ëª© ë¹„êµ
        await test_stock_comparison()

        # í…ŒìŠ¤íŠ¸ 5: ì „ì²´ í”Œë¡œìš°
        await test_vector_search_flow()

        logger.info("\n" + "=" * 80)
        logger.info("âœ… All RAG tests completed successfully!")
        logger.info("=" * 80)

    except Exception as e:
        logger.error(f"âŒ Test suite failed: {str(e)}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
