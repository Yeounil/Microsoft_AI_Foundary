from fastapi import APIRouter, HTTPException, Query, Body
from app.services.claude_service import ClaudeService
from app.db.supabase_client import get_supabase
from typing import Dict, Any, Optional
from datetime import datetime, timedelta
import logging
import json

logger = logging.getLogger(__name__)

router = APIRouter()


@router.post("")
async def create_news_report(
    symbol: str = Body(..., description="ì¢…ëª© ì‹¬ë³¼"),
    limit: int = Body(20, description="ë¶„ì„í•  ë‰´ìŠ¤ ê°œìˆ˜")
):
    """
    ë‰´ìŠ¤ ë¶„ì„ ë ˆí¬íŠ¸ ìƒì„± ë° ì €ì¥ (POST)

    Claude 4.5 Sonnetì„ ì‚¬ìš©í•˜ì—¬ ìµœì‹  ë‰´ìŠ¤ë¥¼ ë¶„ì„í•˜ê³ 
    ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•œ í›„ DBì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: AAPL, GOOGL, TSLA)
        limit: ë¶„ì„í•  ë‰´ìŠ¤ ê°œìˆ˜ (ê¸°ë³¸: 20, ìµœëŒ€: 50)

    Returns:
        {
            "id": 123,
            "symbol": "AAPL",
            "report_data": {...},
            "created_at": "2025-01-08T16:30:00Z",
            "expires_at": "2025-01-09T16:30:00Z"
        }
    """
    try:
        # limit ë²”ìœ„ ì œí•œ
        limit = min(max(limit, 5), 50)
        symbol = symbol.upper()

        supabase = get_supabase()

        logger.info(f"[NEWS_REPORT] {symbol} ë ˆí¬íŠ¸ ìƒì„± ìš”ì²­ (limit: {limit})")

        # 1. ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ
        query_builder = supabase.table("news_articles")\
            .select("id, title, body, url, source, published_at, symbol, positive_score, ai_score, ai_analyzed_text")\
            .eq("symbol", symbol)\
            .order("published_at", desc=True)\
            .limit(limit)

        result = query_builder.execute()

        if not result.data or len(result.data) == 0:
            raise HTTPException(
                status_code=404,
                detail=f"{symbol} ì¢…ëª©ì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        news_articles = result.data
        logger.info(f"[NEWS_REPORT] {len(news_articles)}ê°œ ë‰´ìŠ¤ ì¡°íšŒ ì™„ë£Œ")

        # 2. Claudeë¡œ ë ˆí¬íŠ¸ ìƒì„±
        claude_service = ClaudeService()
        report_data = await claude_service.generate_news_report(
            symbol=symbol,
            news_articles=news_articles
        )

        logger.info(f"[NEWS_REPORT] âœ… {symbol} ë ˆí¬íŠ¸ ìƒì„± ì™„ë£Œ")

        # 3. DBì— ì €ì¥
        expires_at = datetime.now() + timedelta(hours=24)

        insert_data = {
            "symbol": symbol,
            "report_data": report_data,
            "analyzed_count": len(news_articles),
            "limit_used": limit,
            "expires_at": expires_at.isoformat()
        }

        save_result = supabase.table("news_reports").insert(insert_data).execute()

        if not save_result.data or len(save_result.data) == 0:
            logger.error(f"[NEWS_REPORT] DB ì €ì¥ ì‹¤íŒ¨")
            # ì €ì¥ ì‹¤íŒ¨í•´ë„ ë ˆí¬íŠ¸ëŠ” ë°˜í™˜
            return {
                "id": None,
                "symbol": symbol,
                "report_data": report_data,
                "created_at": datetime.now().isoformat(),
                "expires_at": expires_at.isoformat(),
                "saved": False
            }

        saved_report = save_result.data[0]
        logger.info(f"[NEWS_REPORT] ğŸ’¾ ë ˆí¬íŠ¸ DB ì €ì¥ ì™„ë£Œ (ID: {saved_report.get('id')})")

        return {
            "id": saved_report.get("id"),
            "symbol": symbol,
            "report_data": report_data,
            "created_at": saved_report.get("created_at"),
            "expires_at": saved_report.get("expires_at"),
            "saved": True
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[NEWS_REPORT] ë ˆí¬íŠ¸ ìƒì„± ì˜¤ë¥˜ ({symbol}): {str(e)}")
        import traceback
        logger.error(f"[NEWS_REPORT] ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"ë ˆí¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/{symbol}")
async def get_news_report(
    symbol: str,
    force_refresh: bool = Query(False, description="ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„±")
):
    """
    ë‰´ìŠ¤ ë¶„ì„ ë ˆí¬íŠ¸ ì¡°íšŒ (GET)

    DBì—ì„œ ìºì‹œëœ ë ˆí¬íŠ¸ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤ (24ì‹œê°„ ì´ë‚´).
    ìºì‹œê°€ ì—†ê±°ë‚˜ ë§Œë£Œë˜ì—ˆìœ¼ë©´ 404ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼ (ì˜ˆ: AAPL, GOOGL, TSLA)
        force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ìƒì„± ì•ˆë‚´

    Returns:
        ë ˆí¬íŠ¸ ë°ì´í„° ë˜ëŠ” 404 ì—ëŸ¬
    """
    try:
        symbol = symbol.upper()
        supabase = get_supabase()

        logger.info(f"[NEWS_REPORT] {symbol} ë ˆí¬íŠ¸ ì¡°íšŒ")

        if force_refresh:
            raise HTTPException(
                status_code=404,
                detail="ìƒˆë¡œìš´ ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”. POST /api/v1/news-report ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”."
            )

        # DBì—ì„œ ìµœì‹  ë ˆí¬íŠ¸ ì¡°íšŒ (ë§Œë£Œë˜ì§€ ì•Šì€ ê²ƒë§Œ)
        current_time = datetime.now().isoformat()

        query_result = supabase.table("news_reports")\
            .select("*")\
            .eq("symbol", symbol)\
            .gt("expires_at", current_time)\
            .order("created_at", desc=True)\
            .limit(1)\
            .execute()

        if not query_result.data or len(query_result.data) == 0:
            raise HTTPException(
                status_code=404,
                detail=f"{symbol} ì¢…ëª©ì˜ ìœ íš¨í•œ ë ˆí¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ë ˆí¬íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."
            )

        cached_report = query_result.data[0]
        logger.info(f"[NEWS_REPORT] âœ… ìºì‹œëœ ë ˆí¬íŠ¸ ì¡°íšŒ (ID: {cached_report.get('id')})")

        # report_data ì¶”ì¶œ
        report_data = cached_report.get("report_data")

        return {
            "id": cached_report.get("id"),
            "symbol": symbol,
            "report_data": report_data,
            "created_at": cached_report.get("created_at"),
            "expires_at": cached_report.get("expires_at"),
            "from_cache": True
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[NEWS_REPORT] ë ˆí¬íŠ¸ ì¡°íšŒ ì˜¤ë¥˜ ({symbol}): {str(e)}")
        import traceback
        logger.error(f"[NEWS_REPORT] ìƒì„¸ ì˜¤ë¥˜:\n{traceback.format_exc()}")
        raise HTTPException(
            status_code=500,
            detail=f"ë ˆí¬íŠ¸ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )


@router.get("/{symbol}/preview")
async def preview_news_for_report(
    symbol: str,
    limit: int = Query(20, description="ì¡°íšŒí•  ë‰´ìŠ¤ ê°œìˆ˜")
):
    """
    ë ˆí¬íŠ¸ ìƒì„±ì— ì‚¬ìš©ë  ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°

    Args:
        symbol: ì¢…ëª© ì‹¬ë³¼
        limit: ì¡°íšŒí•  ë‰´ìŠ¤ ê°œìˆ˜

    Returns:
        {
            "symbol": "AAPL",
            "total_count": 20,
            "articles": [...]
        }
    """
    try:
        # limit ë²”ìœ„ ì œí•œ
        limit = min(max(limit, 5), 50)

        supabase = get_supabase()

        # ë‰´ìŠ¤ ì¡°íšŒ
        query_builder = supabase.table("news_articles")\
            .select("id, title, published_at, symbol, positive_score, ai_score, ai_analyzed_text")\
            .eq("symbol", symbol.upper())\
            .order("published_at", desc=True)\
            .limit(limit)

        result = query_builder.execute()

        if not result.data:
            raise HTTPException(
                status_code=404,
                detail=f"{symbol} ì¢…ëª©ì˜ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
            )

        return {
            "symbol": symbol.upper(),
            "total_count": len(result.data),
            "articles": result.data
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[NEWS_PREVIEW] ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸° ì˜¤ë¥˜ ({symbol}): {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))
